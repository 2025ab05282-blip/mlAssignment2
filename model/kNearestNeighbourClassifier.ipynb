{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "69999938-a6d8-4f43-a3d1-2e4e0596a1c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69999938-a6d8-4f43-a3d1-2e4e0596a1c8",
        "outputId": "5dd5c741-b241-4afa-f2d9-545d37417982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Shape: (569, 32)\n",
            "Columns: ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
            "Target mapping: {'B': np.int64(0), 'M': np.int64(1)}\n",
            "Train shape: (455, 30) Test shape: (114, 30)\n",
            "Class balance (train): [285 170]\n",
            "Class balance (test): [72 42]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score, recall_score,\n",
        "    f1_score, matthews_corrcoef\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# ========== CHANGE THESE TWO LINES ==========\n",
        "CSV_PATH = \"/content/drive/MyDrive/dataSet/ml/data.csv\"\n",
        "TARGET_COL = \"diagnosis\"   # e.g., \"diagnosis\" or \"target\" (change if needed)\n",
        "# ===========================================\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Drop common junk columns like \"Unnamed: 32\"\n",
        "df = df.loc[:, ~df.columns.str.contains(r\"^Unnamed\", regex=True)]\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Split features/target\n",
        "# Split features/target\n",
        "TARGET_COL = \"diagnosis\"\n",
        "\n",
        "X = df.drop(columns=[TARGET_COL]).copy()\n",
        "\n",
        "# Drop ID if present\n",
        "if \"id\" in X.columns:\n",
        "    X = X.drop(columns=[\"id\"])\n",
        "\n",
        "y_raw = df[TARGET_COL].astype(str)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y_raw)\n",
        "\n",
        "print(\"Target mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "# Typically: {'B': 0, 'M': 1}\n",
        "\n",
        "# Train/test split (stratify keeps class balance)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "print(\"Class balance (train):\", np.bincount(y_train))\n",
        "print(\"Class balance (test):\", np.bincount(y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb697673-117e-4b5a-aaa3-9c43f74cdb48",
      "metadata": {
        "id": "fb697673-117e-4b5a-aaa3-9c43f74cdb48"
      },
      "source": [
        "# k nearnest neighbours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0743343b-ddcf-4b42-9c7d-ce4f9bf1c86c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0743343b-ddcf-4b42-9c7d-ce4f9bf1c86c",
        "outputId": "d600c0d8-0c1d-4280-88fb-dd565a4988bd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mEPERM: operation not permitted, scandir '/Users/HarshitaShaktawat/Downloads/DNN/mlAssignment2/model'. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score, recall_score,\n",
        "    f1_score, matthews_corrcoef\n",
        ")\n",
        "\n",
        "knn = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"model\", KNeighborsClassifier(\n",
        "        n_neighbors=5,      # default baseline\n",
        "        weights=\"distance\", # often better than uniform\n",
        "        metric=\"minkowski\", # Euclidean (p=2) by default\n",
        "        p=2\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# AUC: KNN supports predict_proba\n",
        "y_proba = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Metrics\n",
        "metrics_knn = {\n",
        "    \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "    \"AUC\": roc_auc_score(y_test, y_proba),\n",
        "    \"Precision\": precision_score(y_test, y_pred, zero_division=0),\n",
        "    \"Recall\": recall_score(y_test, y_pred, zero_division=0),\n",
        "    \"F1\": f1_score(y_test, y_pred, zero_division=0),\n",
        "    \"MCC\": matthews_corrcoef(y_test, y_pred),\n",
        "}\n",
        "\n",
        "print(\"\\n=== Model 3: KNN Metrics ===\")\n",
        "for k, v in metrics_knn.items():\n",
        "    print(f\"{k:10s}: {v:.6f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
